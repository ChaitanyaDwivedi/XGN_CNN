{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x,numlabels):\n",
    "    t = [0 for i in range(numlabels)]\n",
    "    t[x-1] = 1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEER_(y_score, y_test):\n",
    "\tn_classes = y_score.shape[1]\n",
    "\tfpr = dict()\n",
    "\ttpr = dict()\n",
    "\troc_auc = dict()\n",
    "\tmissRate = dict()\n",
    "\tfor i in range(n_classes):\n",
    "\t\tfpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "\t\troc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\tfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "\tmissRate[\"micro\"] = 1 - tpr[\"micro\"]\n",
    "\tall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\t# Then interpolate all ROC curves at this points\n",
    "\tmean_tpr = np.zeros_like(all_fpr)\n",
    "\tfor i in range(n_classes):\n",
    "\t\tmean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\tmean_tpr /= n_classes\n",
    "\tfpr[\"macro\"] = all_fpr\n",
    "\ttpr[\"macro\"] = mean_tpr\n",
    "\tmissRate[\"macro\"] = 1 - tpr[\"macro\"]\n",
    "\treturn  min(fpr[\"micro\"][np.argmin(abs(fpr[\"micro\"]-missRate[\"micro\"]))], fpr[\"macro\"][np.argmin(abs(fpr[\"macro\"]-missRate[\"macro\"]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "data= pickle.load(open('/Users/chaitanya/Documents/python/keystrokes/data_augmentation/CMU/CMU2X_dat.pickle','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data['data'])\n",
    "Y = np.array(data['labels'])\n",
    "X = X.reshape(X.shape[0], 31)\n",
    "\n",
    "n = X.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEER(y_score, y_test):\n",
    "    #y_score = y_score.get_label()\n",
    "    y_test = np.array(y_test.get_label()).reshape(len(y_score), 1)\n",
    "    n_classes = y_score.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    missRate = dict()\n",
    "    y_test_ = [onehot(int(x+1), 100) for x in y_test]\n",
    "    y_test = np.reshape(y_test_, (len(y_test_),100))\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    missRate[\"micro\"] = 1 - tpr[\"micro\"]\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    missRate[\"macro\"] = 1 - tpr[\"macro\"]\n",
    "    #print(np.dtype(min(fpr[\"micro\"][np.argmin(abs(fpr[\"micro\"]-missRate[\"micro\"]))], fpr[\"macro\"][np.argmin(abs(fpr[\"macro\"]-missRate[\"macro\"]))])))\n",
    "    return 'EER', min(fpr[\"micro\"][np.argmin(abs(fpr[\"micro\"]-missRate[\"micro\"]))], fpr[\"macro\"][np.argmin(abs(fpr[\"macro\"]-missRate[\"macro\"]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = [np.argmax(x) for x in y_train]\n",
    "y_test_ = [np.argmax(x) for x in y_test]\n",
    "xg_train = xgb.DMatrix(X_train, label = y_train_)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test_)\n",
    "#xg_train_cv = xgb.DMatrix(X_train, label = np.reshape(y_train,(12593,100)))\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':10,\n",
    "    'eval_metric': 'merror',\n",
    "    'min_child_weight': 8,\n",
    "    'eta': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'multi:softprob',\n",
    "    'num_class' : 51,\n",
    "}\n",
    "num_boost_round = 999\n",
    "params['tree_method']= 'hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.134858\n",
      "Will train until Test-merror hasn't improved in 20 rounds.\n",
      "[1]\tTest-merror:0.110022\n",
      "[2]\tTest-merror:0.099455\n",
      "[3]\tTest-merror:0.092375\n",
      "[4]\tTest-merror:0.086383\n",
      "[5]\tTest-merror:0.078758\n",
      "[6]\tTest-merror:0.075272\n",
      "[7]\tTest-merror:0.070697\n",
      "[8]\tTest-merror:0.068627\n",
      "[9]\tTest-merror:0.065033\n",
      "[10]\tTest-merror:0.062636\n",
      "[11]\tTest-merror:0.060893\n",
      "[12]\tTest-merror:0.058497\n",
      "[13]\tTest-merror:0.056209\n",
      "[14]\tTest-merror:0.055229\n",
      "[15]\tTest-merror:0.053595\n",
      "[16]\tTest-merror:0.051634\n",
      "[17]\tTest-merror:0.050218\n",
      "[18]\tTest-merror:0.049673\n",
      "[19]\tTest-merror:0.047821\n",
      "[20]\tTest-merror:0.04695\n",
      "[21]\tTest-merror:0.045752\n",
      "[22]\tTest-merror:0.044662\n",
      "[23]\tTest-merror:0.043791\n",
      "[24]\tTest-merror:0.042702\n",
      "[25]\tTest-merror:0.042375\n",
      "[26]\tTest-merror:0.041721\n",
      "[27]\tTest-merror:0.041503\n",
      "[28]\tTest-merror:0.040414\n",
      "[29]\tTest-merror:0.039651\n",
      "[30]\tTest-merror:0.038998\n",
      "[31]\tTest-merror:0.038235\n",
      "[32]\tTest-merror:0.038344\n",
      "[33]\tTest-merror:0.0378\n",
      "[34]\tTest-merror:0.036819\n",
      "[35]\tTest-merror:0.036275\n",
      "[36]\tTest-merror:0.035948\n",
      "[37]\tTest-merror:0.035512\n",
      "[38]\tTest-merror:0.035185\n",
      "[39]\tTest-merror:0.034314\n",
      "[40]\tTest-merror:0.034205\n",
      "[41]\tTest-merror:0.034096\n",
      "[42]\tTest-merror:0.033551\n",
      "[43]\tTest-merror:0.033333\n",
      "[44]\tTest-merror:0.032789\n",
      "[45]\tTest-merror:0.032789\n",
      "[46]\tTest-merror:0.032135\n",
      "[47]\tTest-merror:0.032026\n",
      "[48]\tTest-merror:0.031699\n",
      "[49]\tTest-merror:0.031373\n",
      "[50]\tTest-merror:0.031155\n",
      "[51]\tTest-merror:0.031264\n",
      "[52]\tTest-merror:0.030174\n",
      "[53]\tTest-merror:0.030283\n",
      "[54]\tTest-merror:0.029521\n",
      "[55]\tTest-merror:0.029521\n",
      "[56]\tTest-merror:0.029956\n",
      "[57]\tTest-merror:0.029521\n",
      "[58]\tTest-merror:0.029521\n",
      "[59]\tTest-merror:0.029303\n",
      "[60]\tTest-merror:0.029085\n",
      "[61]\tTest-merror:0.029194\n",
      "[62]\tTest-merror:0.028649\n",
      "[63]\tTest-merror:0.028758\n",
      "[64]\tTest-merror:0.028649\n",
      "[65]\tTest-merror:0.02854\n",
      "[66]\tTest-merror:0.028431\n",
      "[67]\tTest-merror:0.027996\n",
      "[68]\tTest-merror:0.027887\n",
      "[69]\tTest-merror:0.02756\n",
      "[70]\tTest-merror:0.027342\n",
      "[71]\tTest-merror:0.027124\n",
      "[72]\tTest-merror:0.027015\n",
      "[73]\tTest-merror:0.026797\n",
      "[74]\tTest-merror:0.02658\n",
      "[75]\tTest-merror:0.026253\n",
      "[76]\tTest-merror:0.026035\n",
      "[77]\tTest-merror:0.026035\n",
      "[78]\tTest-merror:0.025817\n",
      "[79]\tTest-merror:0.025272\n",
      "[80]\tTest-merror:0.025708\n",
      "[81]\tTest-merror:0.025381\n",
      "[82]\tTest-merror:0.025163\n",
      "[83]\tTest-merror:0.025163\n",
      "[84]\tTest-merror:0.024946\n",
      "[85]\tTest-merror:0.025163\n",
      "[86]\tTest-merror:0.025163\n",
      "[87]\tTest-merror:0.025163\n",
      "[88]\tTest-merror:0.024946\n",
      "[89]\tTest-merror:0.024728\n",
      "[90]\tTest-merror:0.025054\n",
      "[91]\tTest-merror:0.024619\n",
      "[92]\tTest-merror:0.02451\n",
      "[93]\tTest-merror:0.024183\n",
      "[94]\tTest-merror:0.024292\n",
      "[95]\tTest-merror:0.024292\n",
      "[96]\tTest-merror:0.02451\n",
      "[97]\tTest-merror:0.023965\n",
      "[98]\tTest-merror:0.023856\n",
      "[99]\tTest-merror:0.023856\n",
      "[100]\tTest-merror:0.023965\n",
      "[101]\tTest-merror:0.023965\n",
      "[102]\tTest-merror:0.023856\n",
      "[103]\tTest-merror:0.023856\n",
      "[104]\tTest-merror:0.023965\n",
      "[105]\tTest-merror:0.023747\n",
      "[106]\tTest-merror:0.023965\n",
      "[107]\tTest-merror:0.024074\n",
      "[108]\tTest-merror:0.023965\n",
      "[109]\tTest-merror:0.023747\n",
      "[110]\tTest-merror:0.023747\n",
      "[111]\tTest-merror:0.023747\n",
      "[112]\tTest-merror:0.023747\n",
      "[113]\tTest-merror:0.023856\n",
      "[114]\tTest-merror:0.023856\n",
      "[115]\tTest-merror:0.023529\n",
      "[116]\tTest-merror:0.023529\n",
      "[117]\tTest-merror:0.023529\n",
      "[118]\tTest-merror:0.023529\n",
      "[119]\tTest-merror:0.023529\n",
      "[120]\tTest-merror:0.02342\n",
      "[121]\tTest-merror:0.02342\n",
      "[122]\tTest-merror:0.02342\n",
      "[123]\tTest-merror:0.023529\n",
      "[124]\tTest-merror:0.023203\n",
      "[125]\tTest-merror:0.023203\n",
      "[126]\tTest-merror:0.02342\n",
      "[127]\tTest-merror:0.023312\n",
      "[128]\tTest-merror:0.023312\n",
      "[129]\tTest-merror:0.023094\n",
      "[130]\tTest-merror:0.023203\n",
      "[131]\tTest-merror:0.023203\n",
      "[132]\tTest-merror:0.023203\n",
      "[133]\tTest-merror:0.023094\n",
      "[134]\tTest-merror:0.022985\n",
      "[135]\tTest-merror:0.023094\n",
      "[136]\tTest-merror:0.022985\n",
      "[137]\tTest-merror:0.022876\n",
      "[138]\tTest-merror:0.022876\n",
      "[139]\tTest-merror:0.022876\n",
      "[140]\tTest-merror:0.022876\n",
      "[141]\tTest-merror:0.022985\n",
      "[142]\tTest-merror:0.022985\n",
      "[143]\tTest-merror:0.022985\n",
      "[144]\tTest-merror:0.022985\n",
      "[145]\tTest-merror:0.022658\n",
      "[146]\tTest-merror:0.022658\n",
      "[147]\tTest-merror:0.022549\n",
      "[148]\tTest-merror:0.022767\n",
      "[149]\tTest-merror:0.022876\n",
      "[150]\tTest-merror:0.022767\n",
      "[151]\tTest-merror:0.022658\n",
      "[152]\tTest-merror:0.022658\n",
      "[153]\tTest-merror:0.022767\n",
      "[154]\tTest-merror:0.022658\n",
      "[155]\tTest-merror:0.022658\n",
      "[156]\tTest-merror:0.022767\n",
      "[157]\tTest-merror:0.022658\n",
      "[158]\tTest-merror:0.022549\n",
      "[159]\tTest-merror:0.022549\n",
      "[160]\tTest-merror:0.02244\n",
      "[161]\tTest-merror:0.022331\n",
      "[162]\tTest-merror:0.02244\n",
      "[163]\tTest-merror:0.022331\n",
      "[164]\tTest-merror:0.022222\n",
      "[165]\tTest-merror:0.022222\n",
      "[166]\tTest-merror:0.022113\n",
      "[167]\tTest-merror:0.022113\n",
      "[168]\tTest-merror:0.022004\n",
      "[169]\tTest-merror:0.021895\n",
      "[170]\tTest-merror:0.021895\n",
      "[171]\tTest-merror:0.021786\n",
      "[172]\tTest-merror:0.021678\n",
      "[173]\tTest-merror:0.021786\n",
      "[174]\tTest-merror:0.021786\n",
      "[175]\tTest-merror:0.021786\n",
      "[176]\tTest-merror:0.021786\n",
      "[177]\tTest-merror:0.021786\n",
      "[178]\tTest-merror:0.021678\n",
      "[179]\tTest-merror:0.021786\n",
      "[180]\tTest-merror:0.021786\n",
      "[181]\tTest-merror:0.021786\n",
      "[182]\tTest-merror:0.021895\n",
      "[183]\tTest-merror:0.021786\n",
      "[184]\tTest-merror:0.021895\n",
      "[185]\tTest-merror:0.021786\n",
      "[186]\tTest-merror:0.021786\n",
      "[187]\tTest-merror:0.021786\n",
      "[188]\tTest-merror:0.021786\n",
      "[189]\tTest-merror:0.021786\n",
      "[190]\tTest-merror:0.02146\n",
      "[191]\tTest-merror:0.02146\n",
      "[192]\tTest-merror:0.02146\n",
      "[193]\tTest-merror:0.021569\n",
      "[194]\tTest-merror:0.021678\n",
      "[195]\tTest-merror:0.021678\n",
      "[196]\tTest-merror:0.021569\n",
      "[197]\tTest-merror:0.021569\n",
      "[198]\tTest-merror:0.02146\n",
      "[199]\tTest-merror:0.021678\n",
      "[200]\tTest-merror:0.021678\n",
      "[201]\tTest-merror:0.021678\n",
      "[202]\tTest-merror:0.021786\n",
      "[203]\tTest-merror:0.021786\n",
      "[204]\tTest-merror:0.021786\n",
      "[205]\tTest-merror:0.021569\n",
      "[206]\tTest-merror:0.021786\n",
      "[207]\tTest-merror:0.021569\n",
      "[208]\tTest-merror:0.021786\n",
      "[209]\tTest-merror:0.021895\n",
      "[210]\tTest-merror:0.021678\n",
      "Stopping. Best iteration:\n",
      "[190]\tTest-merror:0.02146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    xg_train,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(xg_test, \"Test\")],\n",
    "    early_stopping_rounds=20,\n",
    "    #feval = GetEER,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52020,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(xg_train.get_label())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003043572984749455"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetEER_(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('CMU.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.027239399999999997 for 110 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tMerror 0.027278000000000004 for 148 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tMerror 0.028066199999999996 for 123 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tMerror 0.027278000000000004 for 121 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tMerror 0.027835200000000004 for 146 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tMerror 0.0284508 for 85 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tMerror 0.027028000000000003 for 143 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tMerror 0.0274702 for 139 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMerror 0.026989599999999996 for 175 rounds\n",
      "Best params: 11, 7, Merror: 0.026989599999999996\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xg_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10,\n",
    "        #feval = GetEER,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, Merror: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=10, min_child_weight=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:32: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.0284508 for 85 rounds\n",
      "CV with max_depth=10, min_child_weight=8\n",
      "\tMerror 0.028316 for 117 rounds\n",
      "CV with max_depth=10, min_child_weight=9\n",
      "\tMerror 0.0284888 for 160 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMerror 0.026989599999999996 for 175 rounds\n",
      "CV with max_depth=11, min_child_weight=8\n",
      "\tMerror 0.028200799999999998 for 127 rounds\n",
      "CV with max_depth=11, min_child_weight=9\n",
      "\tMerror 0.028604199999999996 for 119 rounds\n",
      "CV with max_depth=12, min_child_weight=7\n",
      "\tMerror 0.028277399999999998 for 78 rounds\n",
      "CV with max_depth=12, min_child_weight=8\n",
      "\tMerror 0.0283736 for 150 rounds\n",
      "CV with max_depth=12, min_child_weight=9\n",
      "\tMerror 0.0287774 for 133 rounds\n",
      "CV with max_depth=13, min_child_weight=7\n",
      "\tMerror 0.028681400000000003 for 72 rounds\n",
      "CV with max_depth=13, min_child_weight=8\n",
      "\tMerror 0.028642800000000003 for 117 rounds\n",
      "CV with max_depth=13, min_child_weight=9\n",
      "\tMerror 0.0287582 for 122 rounds\n",
      "Best params: 11, 7, Merror: 0.026989599999999996\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(10,14)\n",
    "    for min_child_weight in range(7,10)\n",
    "]\n",
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xg_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10,\n",
    "        #feval = GetEER,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, Merror: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 11\n",
    "params['min_child_weight'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(10,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.026989599999999996 for 175 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMerror 0.0274702 for 130 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMerror 0.027450999999999996 for 104 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMerror 0.028200600000000003 for 99 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMerror 0.027950799999999998 for 88 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMerror 0.027085599999999998 for 154 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMerror 0.027124199999999998 for 134 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMerror 0.027335599999999998 for 128 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMerror 0.0272588 for 137 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMerror 0.0284122 for 96 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMerror 0.0281236 for 135 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMerror 0.0284506 for 94 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMerror 0.0279892 for 120 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMerror 0.0284892 for 109 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMerror 0.029565199999999996 for 121 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMerror 0.0288352 for 145 rounds\n",
      "Best params: 1.0, 1.0, Merror: 0.026989599999999996\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xg_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best score\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, Merror: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 1.0\n",
    "params['colsample_bytree'] = 1.0\n",
    "params['eta'] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.120261\n",
      "Will train until Test-merror hasn't improved in 20 rounds.\n",
      "[1]\tTest-merror:0.097168\n",
      "[2]\tTest-merror:0.086928\n",
      "[3]\tTest-merror:0.082244\n",
      "[4]\tTest-merror:0.076688\n",
      "[5]\tTest-merror:0.072331\n",
      "[6]\tTest-merror:0.068627\n",
      "[7]\tTest-merror:0.06634\n",
      "[8]\tTest-merror:0.063072\n",
      "[9]\tTest-merror:0.06122\n",
      "[10]\tTest-merror:0.059041\n",
      "[11]\tTest-merror:0.05719\n",
      "[12]\tTest-merror:0.055447\n",
      "[13]\tTest-merror:0.054139\n",
      "[14]\tTest-merror:0.052614\n",
      "[15]\tTest-merror:0.05098\n",
      "[16]\tTest-merror:0.050218\n",
      "[17]\tTest-merror:0.049129\n",
      "[18]\tTest-merror:0.048039\n",
      "[19]\tTest-merror:0.047059\n",
      "[20]\tTest-merror:0.046841\n",
      "[21]\tTest-merror:0.046296\n",
      "[22]\tTest-merror:0.04488\n",
      "[23]\tTest-merror:0.044444\n",
      "[24]\tTest-merror:0.043355\n",
      "[25]\tTest-merror:0.043246\n",
      "[26]\tTest-merror:0.042484\n",
      "[27]\tTest-merror:0.041721\n",
      "[28]\tTest-merror:0.041176\n",
      "[29]\tTest-merror:0.040632\n",
      "[30]\tTest-merror:0.040523\n",
      "[31]\tTest-merror:0.039434\n",
      "[32]\tTest-merror:0.03878\n",
      "[33]\tTest-merror:0.037582\n",
      "[34]\tTest-merror:0.037037\n",
      "[35]\tTest-merror:0.036492\n",
      "[36]\tTest-merror:0.036492\n",
      "[37]\tTest-merror:0.036057\n",
      "[38]\tTest-merror:0.035294\n",
      "[39]\tTest-merror:0.034858\n",
      "[40]\tTest-merror:0.034749\n",
      "[41]\tTest-merror:0.034314\n",
      "[42]\tTest-merror:0.034096\n",
      "[43]\tTest-merror:0.033551\n",
      "[44]\tTest-merror:0.033115\n",
      "[45]\tTest-merror:0.033333\n",
      "[46]\tTest-merror:0.032898\n",
      "[47]\tTest-merror:0.032462\n",
      "[48]\tTest-merror:0.032462\n",
      "[49]\tTest-merror:0.031699\n",
      "[50]\tTest-merror:0.03159\n",
      "[51]\tTest-merror:0.031155\n",
      "[52]\tTest-merror:0.031155\n",
      "[53]\tTest-merror:0.03061\n",
      "[54]\tTest-merror:0.030719\n",
      "[55]\tTest-merror:0.03061\n",
      "[56]\tTest-merror:0.030283\n",
      "[57]\tTest-merror:0.029956\n",
      "[58]\tTest-merror:0.030065\n",
      "[59]\tTest-merror:0.029739\n",
      "[60]\tTest-merror:0.02963\n",
      "[61]\tTest-merror:0.029521\n",
      "[62]\tTest-merror:0.029303\n",
      "[63]\tTest-merror:0.029303\n",
      "[64]\tTest-merror:0.02854\n",
      "[65]\tTest-merror:0.029085\n",
      "[66]\tTest-merror:0.028758\n",
      "[67]\tTest-merror:0.02854\n",
      "[68]\tTest-merror:0.028431\n",
      "[69]\tTest-merror:0.027778\n",
      "[70]\tTest-merror:0.02756\n",
      "[71]\tTest-merror:0.027342\n",
      "[72]\tTest-merror:0.027015\n",
      "[73]\tTest-merror:0.026906\n",
      "[74]\tTest-merror:0.02658\n",
      "[75]\tTest-merror:0.026688\n",
      "[76]\tTest-merror:0.026471\n",
      "[77]\tTest-merror:0.026362\n",
      "[78]\tTest-merror:0.026144\n",
      "[79]\tTest-merror:0.025708\n",
      "[80]\tTest-merror:0.025599\n",
      "[81]\tTest-merror:0.02549\n",
      "[82]\tTest-merror:0.02549\n",
      "[83]\tTest-merror:0.025599\n",
      "[84]\tTest-merror:0.025272\n",
      "[85]\tTest-merror:0.02549\n",
      "[86]\tTest-merror:0.025272\n",
      "[87]\tTest-merror:0.025163\n",
      "[88]\tTest-merror:0.025054\n",
      "[89]\tTest-merror:0.025054\n",
      "[90]\tTest-merror:0.024728\n",
      "[91]\tTest-merror:0.024946\n",
      "[92]\tTest-merror:0.024728\n",
      "[93]\tTest-merror:0.024619\n",
      "[94]\tTest-merror:0.02451\n",
      "[95]\tTest-merror:0.024401\n",
      "[96]\tTest-merror:0.024619\n",
      "[97]\tTest-merror:0.024401\n",
      "[98]\tTest-merror:0.02451\n",
      "[99]\tTest-merror:0.024292\n",
      "[100]\tTest-merror:0.024292\n",
      "[101]\tTest-merror:0.024292\n",
      "[102]\tTest-merror:0.024401\n",
      "[103]\tTest-merror:0.02451\n",
      "[104]\tTest-merror:0.02451\n",
      "[105]\tTest-merror:0.02451\n",
      "[106]\tTest-merror:0.024401\n",
      "[107]\tTest-merror:0.02451\n",
      "[108]\tTest-merror:0.02451\n",
      "[109]\tTest-merror:0.024401\n",
      "[110]\tTest-merror:0.024401\n",
      "[111]\tTest-merror:0.024292\n",
      "[112]\tTest-merror:0.024292\n",
      "[113]\tTest-merror:0.024292\n",
      "[114]\tTest-merror:0.024183\n",
      "[115]\tTest-merror:0.024183\n",
      "[116]\tTest-merror:0.024292\n",
      "[117]\tTest-merror:0.024183\n",
      "[118]\tTest-merror:0.024292\n",
      "[119]\tTest-merror:0.024292\n",
      "[120]\tTest-merror:0.024292\n",
      "[121]\tTest-merror:0.024292\n",
      "[122]\tTest-merror:0.024292\n",
      "[123]\tTest-merror:0.024292\n",
      "[124]\tTest-merror:0.024401\n",
      "[125]\tTest-merror:0.024183\n",
      "[126]\tTest-merror:0.024183\n",
      "[127]\tTest-merror:0.024074\n",
      "[128]\tTest-merror:0.024183\n",
      "[129]\tTest-merror:0.024074\n",
      "[130]\tTest-merror:0.024183\n",
      "[131]\tTest-merror:0.024183\n",
      "[132]\tTest-merror:0.023856\n",
      "[133]\tTest-merror:0.023856\n",
      "[134]\tTest-merror:0.023856\n",
      "[135]\tTest-merror:0.023965\n",
      "[136]\tTest-merror:0.023965\n",
      "[137]\tTest-merror:0.023965\n",
      "[138]\tTest-merror:0.023638\n",
      "[139]\tTest-merror:0.023638\n",
      "[140]\tTest-merror:0.023529\n",
      "[141]\tTest-merror:0.02342\n",
      "[142]\tTest-merror:0.023529\n",
      "[143]\tTest-merror:0.023529\n",
      "[144]\tTest-merror:0.023529\n",
      "[145]\tTest-merror:0.02342\n",
      "[146]\tTest-merror:0.02342\n",
      "[147]\tTest-merror:0.023203\n",
      "[148]\tTest-merror:0.023203\n",
      "[149]\tTest-merror:0.023094\n",
      "[150]\tTest-merror:0.022985\n",
      "[151]\tTest-merror:0.022985\n",
      "[152]\tTest-merror:0.022985\n",
      "[153]\tTest-merror:0.022985\n",
      "[154]\tTest-merror:0.022658\n",
      "[155]\tTest-merror:0.022767\n",
      "[156]\tTest-merror:0.022876\n",
      "[157]\tTest-merror:0.022658\n",
      "[158]\tTest-merror:0.022767\n",
      "[159]\tTest-merror:0.022876\n",
      "[160]\tTest-merror:0.022876\n",
      "[161]\tTest-merror:0.022767\n",
      "[162]\tTest-merror:0.022658\n",
      "[163]\tTest-merror:0.022549\n",
      "[164]\tTest-merror:0.022549\n",
      "[165]\tTest-merror:0.022658\n",
      "[166]\tTest-merror:0.022658\n",
      "[167]\tTest-merror:0.022985\n",
      "[168]\tTest-merror:0.022876\n",
      "[169]\tTest-merror:0.022876\n",
      "[170]\tTest-merror:0.022767\n",
      "[171]\tTest-merror:0.022876\n",
      "[172]\tTest-merror:0.022767\n",
      "[173]\tTest-merror:0.022767\n",
      "[174]\tTest-merror:0.022767\n",
      "[175]\tTest-merror:0.022549\n",
      "[176]\tTest-merror:0.022658\n",
      "[177]\tTest-merror:0.022549\n",
      "[178]\tTest-merror:0.022549\n",
      "[179]\tTest-merror:0.022549\n",
      "[180]\tTest-merror:0.02244\n",
      "[181]\tTest-merror:0.022549\n",
      "[182]\tTest-merror:0.02244\n",
      "[183]\tTest-merror:0.022549\n",
      "[184]\tTest-merror:0.022331\n",
      "[185]\tTest-merror:0.022331\n",
      "[186]\tTest-merror:0.022222\n",
      "[187]\tTest-merror:0.022331\n",
      "[188]\tTest-merror:0.022222\n",
      "[189]\tTest-merror:0.02244\n",
      "[190]\tTest-merror:0.02244\n",
      "[191]\tTest-merror:0.022549\n",
      "[192]\tTest-merror:0.02244\n",
      "[193]\tTest-merror:0.022004\n",
      "[194]\tTest-merror:0.022004\n",
      "[195]\tTest-merror:0.022113\n",
      "[196]\tTest-merror:0.022004\n",
      "[197]\tTest-merror:0.022113\n",
      "[198]\tTest-merror:0.022004\n",
      "[199]\tTest-merror:0.021895\n",
      "[200]\tTest-merror:0.022004\n",
      "[201]\tTest-merror:0.022004\n",
      "[202]\tTest-merror:0.022004\n",
      "[203]\tTest-merror:0.022004\n",
      "[204]\tTest-merror:0.021895\n",
      "[205]\tTest-merror:0.022004\n",
      "[206]\tTest-merror:0.022004\n",
      "[207]\tTest-merror:0.022004\n",
      "[208]\tTest-merror:0.022004\n",
      "[209]\tTest-merror:0.021895\n",
      "[210]\tTest-merror:0.022004\n",
      "[211]\tTest-merror:0.021895\n",
      "[212]\tTest-merror:0.022004\n",
      "[213]\tTest-merror:0.021895\n",
      "[214]\tTest-merror:0.021895\n",
      "[215]\tTest-merror:0.021895\n",
      "[216]\tTest-merror:0.021895\n",
      "[217]\tTest-merror:0.021895\n",
      "[218]\tTest-merror:0.021895\n",
      "[219]\tTest-merror:0.021895\n",
      "Stopping. Best iteration:\n",
      "[199]\tTest-merror:0.021895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    xg_train,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(xg_test, \"Test\")],\n",
    "    early_stopping_rounds=20,\n",
    "    #feval = GetEER,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0034531590413943354"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetEER_(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3\r\n"
     ]
    }
   ],
   "source": [
    "!which python3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3.6\r\n"
     ]
    }
   ],
   "source": [
    "!which python3.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
