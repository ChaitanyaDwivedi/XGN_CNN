{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "import pickle\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy import interp\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "data= pickle.load(open('/Users/chaitanya/Documents/python/keystrokes/data_augmentation/greyc1/PCA_GREYC_2X.pickle','rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(x,numlabels):\n",
    "    t = [0 for i in range(numlabels)]\n",
    "    t[x-1] = 1\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEER_(y_score, y_test):\n",
    "\tn_classes = y_score.shape[1]\n",
    "\tfpr = dict()\n",
    "\ttpr = dict()\n",
    "\troc_auc = dict()\n",
    "\tmissRate = dict()\n",
    "\tfor i in range(n_classes):\n",
    "\t\tfpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "\t\troc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\tfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "\tmissRate[\"micro\"] = 1 - tpr[\"micro\"]\n",
    "\tall_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\t# Then interpolate all ROC curves at this points\n",
    "\tmean_tpr = np.zeros_like(all_fpr)\n",
    "\tfor i in range(n_classes):\n",
    "\t\tmean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\tmean_tpr /= n_classes\n",
    "\tfpr[\"macro\"] = all_fpr\n",
    "\ttpr[\"macro\"] = mean_tpr\n",
    "\tmissRate[\"macro\"] = 1 - tpr[\"macro\"]\n",
    "\treturn  min(fpr[\"micro\"][np.argmin(abs(fpr[\"micro\"]-missRate[\"micro\"]))], fpr[\"macro\"][np.argmin(abs(fpr[\"macro\"]-missRate[\"macro\"]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetEER(y_score, y_test):\n",
    "    #y_score = y_score.get_label()\n",
    "    y_test = np.array(y_test.get_label()).reshape(len(y_score), 1)\n",
    "    n_classes = y_score.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    missRate = dict()\n",
    "    y_test_ = [onehot(int(x+1), 100) for x in y_test]\n",
    "    y_test = np.reshape(y_test_, (len(y_test_),100))\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    missRate[\"micro\"] = 1 - tpr[\"micro\"]\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    # Then interpolate all ROC curves at this points\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    missRate[\"macro\"] = 1 - tpr[\"macro\"]\n",
    "    #print(np.dtype(min(fpr[\"micro\"][np.argmin(abs(fpr[\"micro\"]-missRate[\"micro\"]))], fpr[\"macro\"][np.argmin(abs(fpr[\"macro\"]-missRate[\"macro\"]))])))\n",
    "    return 'EER', min(fpr[\"micro\"][np.argmin(abs(fpr[\"micro\"]-missRate[\"micro\"]))], fpr[\"macro\"][np.argmin(abs(fpr[\"macro\"]-missRate[\"macro\"]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2223, 2223, 12593, 12593]\n"
     ]
    }
   ],
   "source": [
    "X = data['data']\n",
    "X = np.array(X).reshape(len(X), 28)\n",
    "y = np.array(data['labels']).reshape(len(X), 100)\n",
    "#X = X[:100,:]\n",
    "#y = y[:100,:]\n",
    "#y_train = [onehot(x,100) for x in train_data['labels']]\n",
    "#X_test = np.array(test_data['features']).reshape(len(test_data['features']), 1, 28, 1)\n",
    "#y_test = [onehot(x,100) for x in test_data['labels']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=12)\n",
    "#X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=122)\n",
    "print([len(x) for x in [X_test, y_test, X_train, y_train]])\n",
    "\n",
    "#y_train=np.reshape(y_train,(len(y_train)*100))\n",
    "#y_test = np.reshape(y_test, (len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = [np.argmax(x) for x in y_train]\n",
    "y_test_ = [np.argmax(x) for x in y_test]\n",
    "xg_train = xgb.DMatrix(X_train, label = y_train_)\n",
    "xg_test = xgb.DMatrix(X_test, label = y_test_)\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':6,\n",
    "    'eval_metric': 'merror',\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.3,\n",
    "    'subsample': 1,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'multi:softprob',\n",
    "    'num_class' : 100,\n",
    "}\n",
    "num_boost_round = 999\n",
    "params['tree_method']= 'hist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.299595\tTest-EER:0.133185\n",
      "Multiple eval metrics have been passed: 'Test-EER' will be used for early stopping.\n",
      "\n",
      "Will train until Test-EER hasn't improved in 10 rounds.\n",
      "[1]\tTest-merror:0.277103\tTest-EER:0.109262\n",
      "[2]\tTest-merror:0.255511\tTest-EER:0.099347\n",
      "[3]\tTest-merror:0.238866\tTest-EER:0.087369\n",
      "[4]\tTest-merror:0.22897\tTest-EER:0.080917\n",
      "[5]\tTest-merror:0.221772\tTest-EER:0.074265\n",
      "[6]\tTest-merror:0.213675\tTest-EER:0.072225\n",
      "[7]\tTest-merror:0.210526\tTest-EER:0.069262\n",
      "[8]\tTest-merror:0.205128\tTest-EER:0.066345\n",
      "[9]\tTest-merror:0.20108\tTest-EER:0.062655\n",
      "[10]\tTest-merror:0.197931\tTest-EER:0.060879\n",
      "[11]\tTest-merror:0.191633\tTest-EER:0.060345\n",
      "[12]\tTest-merror:0.190283\tTest-EER:0.058402\n",
      "[13]\tTest-merror:0.185335\tTest-EER:0.057107\n",
      "[14]\tTest-merror:0.184435\tTest-EER:0.055153\n",
      "[15]\tTest-merror:0.180387\tTest-EER:0.05477\n",
      "[16]\tTest-merror:0.177688\tTest-EER:0.052872\n",
      "[17]\tTest-merror:0.174989\tTest-EER:0.052441\n",
      "[18]\tTest-merror:0.17139\tTest-EER:0.050923\n",
      "[19]\tTest-merror:0.17049\tTest-EER:0.048288\n",
      "[20]\tTest-merror:0.17139\tTest-EER:0.048056\n",
      "[21]\tTest-merror:0.167791\tTest-EER:0.04707\n",
      "[22]\tTest-merror:0.167791\tTest-EER:0.047043\n",
      "[23]\tTest-merror:0.167791\tTest-EER:0.04557\n",
      "[24]\tTest-merror:0.167341\tTest-EER:0.046259\n",
      "[25]\tTest-merror:0.164642\tTest-EER:0.044821\n",
      "[26]\tTest-merror:0.165092\tTest-EER:0.044232\n",
      "[27]\tTest-merror:0.163293\tTest-EER:0.041723\n",
      "[28]\tTest-merror:0.161943\tTest-EER:0.044016\n",
      "[29]\tTest-merror:0.161044\tTest-EER:0.043953\n",
      "[30]\tTest-merror:0.159694\tTest-EER:0.043617\n",
      "[31]\tTest-merror:0.159694\tTest-EER:0.04332\n",
      "[32]\tTest-merror:0.160144\tTest-EER:0.041723\n",
      "[33]\tTest-merror:0.157445\tTest-EER:0.042844\n",
      "[34]\tTest-merror:0.157445\tTest-EER:0.042254\n",
      "[35]\tTest-merror:0.156545\tTest-EER:0.04263\n",
      "[36]\tTest-merror:0.156995\tTest-EER:0.04263\n",
      "[37]\tTest-merror:0.155646\tTest-EER:0.042177\n",
      "Stopping. Best iteration:\n",
      "[27]\tTest-merror:0.163293\tTest-EER:0.041723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    params,\n",
    "    xg_train,\n",
    "    num_boost_round=num_boost_round,\n",
    "    evals=[(xg_test, \"Test\")],\n",
    "    early_stopping_rounds=10,\n",
    "    feval = GetEER,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04217687074829932"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(xg_test)\n",
    "GetEER_(pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-dbe882346193>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'merror'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfeval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetEER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    404\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 894\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    895\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    xg_train,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'merror'},\n",
    "    early_stopping_rounds=10,\n",
    "    feval = GetEER,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-merror-mean</th>\n",
       "      <th>train-merror-std</th>\n",
       "      <th>test-merror-mean</th>\n",
       "      <th>test-merror-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219706</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.302707</td>\n",
       "      <td>0.011303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166938</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.285238</td>\n",
       "      <td>0.009576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.126916</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>0.264591</td>\n",
       "      <td>0.008174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.104324</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.246089</td>\n",
       "      <td>0.006187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.089216</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.234574</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.073910</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.226554</td>\n",
       "      <td>0.008428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.060073</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.217978</td>\n",
       "      <td>0.008516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.046454</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.213769</td>\n",
       "      <td>0.007248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.034960</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.209640</td>\n",
       "      <td>0.006373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.026086</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>0.204717</td>\n",
       "      <td>0.006018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.018681</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.199079</td>\n",
       "      <td>0.005798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.013142</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.196220</td>\n",
       "      <td>0.006871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.191614</td>\n",
       "      <td>0.007060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006154</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.188756</td>\n",
       "      <td>0.007779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.004090</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.186373</td>\n",
       "      <td>0.007685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.184468</td>\n",
       "      <td>0.008339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001886</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.181927</td>\n",
       "      <td>0.008496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.008366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.178750</td>\n",
       "      <td>0.008717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.177162</td>\n",
       "      <td>0.008204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.175097</td>\n",
       "      <td>0.009080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.173827</td>\n",
       "      <td>0.009222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.172635</td>\n",
       "      <td>0.008950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171524</td>\n",
       "      <td>0.009627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.169935</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.009840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.167792</td>\n",
       "      <td>0.009855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.166918</td>\n",
       "      <td>0.009635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.165489</td>\n",
       "      <td>0.009134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164854</td>\n",
       "      <td>0.008614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150957</td>\n",
       "      <td>0.008020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151037</td>\n",
       "      <td>0.007781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150640</td>\n",
       "      <td>0.007797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150560</td>\n",
       "      <td>0.007926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150640</td>\n",
       "      <td>0.008080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150322</td>\n",
       "      <td>0.008176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150084</td>\n",
       "      <td>0.008108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150004</td>\n",
       "      <td>0.007608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150004</td>\n",
       "      <td>0.007801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150322</td>\n",
       "      <td>0.007977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150163</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150084</td>\n",
       "      <td>0.007831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150004</td>\n",
       "      <td>0.007596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149607</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149766</td>\n",
       "      <td>0.007850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150084</td>\n",
       "      <td>0.007888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150243</td>\n",
       "      <td>0.008072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149766</td>\n",
       "      <td>0.008307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149687</td>\n",
       "      <td>0.007832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149687</td>\n",
       "      <td>0.008086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149687</td>\n",
       "      <td>0.007957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149528</td>\n",
       "      <td>0.007775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149369</td>\n",
       "      <td>0.008007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149210</td>\n",
       "      <td>0.008030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148972</td>\n",
       "      <td>0.008213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.008123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148813</td>\n",
       "      <td>0.008120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148813</td>\n",
       "      <td>0.008357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148416</td>\n",
       "      <td>0.008034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.148178</td>\n",
       "      <td>0.008186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-merror-mean  train-merror-std  test-merror-mean  test-merror-std\n",
       "0             0.219706          0.001887          0.302707         0.011303\n",
       "1             0.166938          0.002620          0.285238         0.009576\n",
       "2             0.126916          0.001585          0.264591         0.008174\n",
       "3             0.104324          0.002049          0.246089         0.006187\n",
       "4             0.089216          0.002075          0.234574         0.006100\n",
       "5             0.073910          0.001888          0.226554         0.008428\n",
       "6             0.060073          0.001529          0.217978         0.008516\n",
       "7             0.046454          0.001211          0.213769         0.007248\n",
       "8             0.034960          0.000816          0.209640         0.006373\n",
       "9             0.026086          0.001223          0.204717         0.006018\n",
       "10            0.018681          0.000846          0.199079         0.005798\n",
       "11            0.013142          0.000853          0.196220         0.006871\n",
       "12            0.009013          0.000680          0.191614         0.007060\n",
       "13            0.006154          0.000494          0.188756         0.007779\n",
       "14            0.004090          0.000553          0.186373         0.007685\n",
       "15            0.002779          0.000461          0.184468         0.008339\n",
       "16            0.001886          0.000355          0.181927         0.008496\n",
       "17            0.001191          0.000108          0.180100         0.008366\n",
       "18            0.000854          0.000173          0.178750         0.008717\n",
       "19            0.000675          0.000146          0.177162         0.008204\n",
       "20            0.000357          0.000048          0.175097         0.009080\n",
       "21            0.000239          0.000048          0.173827         0.009222\n",
       "22            0.000159          0.000080          0.172635         0.008950\n",
       "23            0.000099          0.000000          0.171524         0.009627\n",
       "24            0.000079          0.000040          0.169935         0.009682\n",
       "25            0.000020          0.000040          0.169697         0.009840\n",
       "26            0.000020          0.000040          0.167792         0.009855\n",
       "27            0.000020          0.000040          0.166918         0.009635\n",
       "28            0.000020          0.000040          0.165489         0.009134\n",
       "29            0.000000          0.000000          0.164854         0.008614\n",
       "..                 ...               ...               ...              ...\n",
       "72            0.000000          0.000000          0.150957         0.008020\n",
       "73            0.000000          0.000000          0.151037         0.007781\n",
       "74            0.000000          0.000000          0.150640         0.007797\n",
       "75            0.000000          0.000000          0.150560         0.007926\n",
       "76            0.000000          0.000000          0.150640         0.008080\n",
       "77            0.000000          0.000000          0.150322         0.008176\n",
       "78            0.000000          0.000000          0.150084         0.008108\n",
       "79            0.000000          0.000000          0.150004         0.007608\n",
       "80            0.000000          0.000000          0.150004         0.007801\n",
       "81            0.000000          0.000000          0.150322         0.007977\n",
       "82            0.000000          0.000000          0.150163         0.008000\n",
       "83            0.000000          0.000000          0.150084         0.007831\n",
       "84            0.000000          0.000000          0.150004         0.007596\n",
       "85            0.000000          0.000000          0.149607         0.007874\n",
       "86            0.000000          0.000000          0.149766         0.007850\n",
       "87            0.000000          0.000000          0.150084         0.007888\n",
       "88            0.000000          0.000000          0.150243         0.008072\n",
       "89            0.000000          0.000000          0.149766         0.008307\n",
       "90            0.000000          0.000000          0.149687         0.007832\n",
       "91            0.000000          0.000000          0.149687         0.008086\n",
       "92            0.000000          0.000000          0.149687         0.007957\n",
       "93            0.000000          0.000000          0.149528         0.007775\n",
       "94            0.000000          0.000000          0.149369         0.008007\n",
       "95            0.000000          0.000000          0.149210         0.008030\n",
       "96            0.000000          0.000000          0.148972         0.008213\n",
       "97            0.000000          0.000000          0.148893         0.008123\n",
       "98            0.000000          0.000000          0.148813         0.008120\n",
       "99            0.000000          0.000000          0.148813         0.008357\n",
       "100           0.000000          0.000000          0.148416         0.008034\n",
       "101           0.000000          0.000000          0.148178         0.008186\n",
       "\n",
       "[102 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.122211 for 119 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-eb84a0b32f43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'merror'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfeval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGetEER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, iteration, feval)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;34m\"\"\"\"Evaluate the CVPack for one iteration.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m                 \u001b[0mfeval_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-161-174b828c311f>\u001b[0m in \u001b[0;36mGetEER\u001b[0;34m(y_score, y_test)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmissRate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0my_test_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-161-174b828c311f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmissRate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0my_test_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-ac9ed310ed80>\u001b[0m in \u001b[0;36monehot\u001b[0;34m(x, numlabels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0monehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xg_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10,\n",
    "        feval = GetEER,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, Merror: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=10, min_child_weight=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:30: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.1170488 for 71 rounds\n",
      "CV with max_depth=10, min_child_weight=8\n",
      "\tMerror 0.1141906 for 93 rounds\n",
      "CV with max_depth=10, min_child_weight=9\n",
      "\tMerror 0.1146672 for 76 rounds\n",
      "CV with max_depth=10, min_child_weight=10\n",
      "\tMerror 0.1146674 for 61 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tMerror 0.1170488 for 71 rounds\n",
      "CV with max_depth=11, min_child_weight=8\n",
      "\tMerror 0.1141906 for 93 rounds\n",
      "CV with max_depth=11, min_child_weight=9\n",
      "\tMerror 0.1146672 for 76 rounds\n",
      "CV with max_depth=11, min_child_weight=10\n",
      "\tMerror 0.1146674 for 61 rounds\n",
      "CV with max_depth=12, min_child_weight=7\n",
      "\tMerror 0.1170488 for 71 rounds\n",
      "CV with max_depth=12, min_child_weight=8\n",
      "\tMerror 0.1141906 for 93 rounds\n",
      "CV with max_depth=12, min_child_weight=9\n",
      "\tMerror 0.1146672 for 76 rounds\n",
      "CV with max_depth=12, min_child_weight=10\n",
      "\tMerror 0.1146674 for 61 rounds\n",
      "Best params: 10, 8, Merror: 0.1141906\n"
     ]
    }
   ],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(10,13)\n",
    "    for min_child_weight in range(7,11)\n",
    "]\n",
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xg_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # Update best MAE\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, Merror: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 10\n",
    "params['min_child_weight'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.1141906 for 93 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tMerror 0.1158584 for 61 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tMerror 0.1166528 for 66 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tMerror 0.1137942 for 75 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tMerror 0.11403160000000001 for 48 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tMerror 0.11506419999999999 for 46 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tMerror 0.11387320000000001 for 72 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tMerror 0.1138738 for 89 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tMerror 0.11220539999999998 for 102 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tMerror 0.1123644 for 77 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tMerror 0.11236439999999999 for 77 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tMerror 0.1150646 for 64 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tMerror 0.114429 for 70 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tMerror 0.11514359999999998 for 47 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tMerror 0.11482620000000002 for 53 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tMerror 0.1156204 for 46 rounds\n",
      "Best params: 0.8, 1.0, Merror: 0.11220539999999998\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        xg_train,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Update best score\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, Merror: {}\".format(best_params[0], best_params[1], min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 0.8\n",
    "params['colsample_bytree'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with eta=0.3\n",
      "CPU times: user 6 µs, sys: 1 µs, total: 7 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.11220539999999998 for 102 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 12.2 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.11037919999999998 for 79 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.11093519999999998 for 140 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 11.9 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMerror 0.10990300000000001 for 245 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 12.2 µs\n",
      "\tMerror 0.13563119999999998 for 403 rounds\n",
      "\n",
      "Best params: 0.05, Merror: 0.12506940000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: 'argmin' is deprecated, use 'idxmin' instead. The behavior of 'argmin'\n",
      "will be corrected to return the positional minimum in the future.\n",
      "Use 'series.values.argmin' to get the position of the minimum now.\n"
     ]
    }
   ],
   "source": [
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "    %time\n",
    "    # Run and time CV\n",
    "    cv_results = xgb.cv(\n",
    "            params,\n",
    "            xg_train,\n",
    "            num_boost_round=num_boost_round,\n",
    "            seed=42,\n",
    "            nfold=5,\n",
    "            metrics=['merror'],\n",
    "            early_stopping_rounds=10\n",
    "          )\n",
    "\n",
    "    # Update best score\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    print(\"\\tMerror {} for {} rounds\\n\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_mae\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, Merror: {}\".format(best_params, min_merror))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.540261\n",
      "Will train until Test-merror hasn't improved in 20 rounds.\n",
      "[1]\tTest-merror:0.383266\n",
      "[2]\tTest-merror:0.316239\n",
      "[3]\tTest-merror:0.272605\n",
      "[4]\tTest-merror:0.254611\n",
      "[5]\tTest-merror:0.236617\n",
      "[6]\tTest-merror:0.226271\n",
      "[7]\tTest-merror:0.220873\n",
      "[8]\tTest-merror:0.214575\n",
      "[9]\tTest-merror:0.212326\n",
      "[10]\tTest-merror:0.206478\n",
      "[11]\tTest-merror:0.202879\n",
      "[12]\tTest-merror:0.20018\n",
      "[13]\tTest-merror:0.197931\n",
      "[14]\tTest-merror:0.194782\n",
      "[15]\tTest-merror:0.194332\n",
      "[16]\tTest-merror:0.192533\n",
      "[17]\tTest-merror:0.189384\n",
      "[18]\tTest-merror:0.188484\n",
      "[19]\tTest-merror:0.185335\n",
      "[20]\tTest-merror:0.183986\n",
      "[21]\tTest-merror:0.181287\n",
      "[22]\tTest-merror:0.179487\n",
      "[23]\tTest-merror:0.176788\n",
      "[24]\tTest-merror:0.176788\n",
      "[25]\tTest-merror:0.174989\n",
      "[26]\tTest-merror:0.174089\n",
      "[27]\tTest-merror:0.173189\n",
      "[28]\tTest-merror:0.17004\n",
      "[29]\tTest-merror:0.17004\n",
      "[30]\tTest-merror:0.169591\n",
      "[31]\tTest-merror:0.168691\n",
      "[32]\tTest-merror:0.167791\n",
      "[33]\tTest-merror:0.166442\n",
      "[34]\tTest-merror:0.165542\n",
      "[35]\tTest-merror:0.165092\n",
      "[36]\tTest-merror:0.163743\n",
      "[37]\tTest-merror:0.161044\n",
      "[38]\tTest-merror:0.160594\n",
      "[39]\tTest-merror:0.159694\n",
      "[40]\tTest-merror:0.158345\n",
      "[41]\tTest-merror:0.157445\n",
      "[42]\tTest-merror:0.156095\n",
      "[43]\tTest-merror:0.154746\n",
      "[44]\tTest-merror:0.153396\n",
      "[45]\tTest-merror:0.152497\n",
      "[46]\tTest-merror:0.150697\n",
      "[47]\tTest-merror:0.150247\n",
      "[48]\tTest-merror:0.149798\n",
      "[49]\tTest-merror:0.148898\n",
      "[50]\tTest-merror:0.147998\n",
      "[51]\tTest-merror:0.147998\n",
      "[52]\tTest-merror:0.147998\n",
      "[53]\tTest-merror:0.147548\n",
      "[54]\tTest-merror:0.148448\n",
      "[55]\tTest-merror:0.147998\n",
      "[56]\tTest-merror:0.147548\n",
      "[57]\tTest-merror:0.147099\n",
      "[58]\tTest-merror:0.146199\n",
      "[59]\tTest-merror:0.145299\n",
      "[60]\tTest-merror:0.145299\n",
      "[61]\tTest-merror:0.144849\n",
      "[62]\tTest-merror:0.144399\n",
      "[63]\tTest-merror:0.14395\n",
      "[64]\tTest-merror:0.1426\n",
      "[65]\tTest-merror:0.140801\n",
      "[66]\tTest-merror:0.140351\n",
      "[67]\tTest-merror:0.139451\n",
      "[68]\tTest-merror:0.139901\n",
      "[69]\tTest-merror:0.138552\n",
      "[70]\tTest-merror:0.137202\n",
      "[71]\tTest-merror:0.137202\n",
      "[72]\tTest-merror:0.137202\n",
      "[73]\tTest-merror:0.137652\n",
      "[74]\tTest-merror:0.138102\n",
      "[75]\tTest-merror:0.136752\n",
      "[76]\tTest-merror:0.135403\n",
      "[77]\tTest-merror:0.134053\n",
      "[78]\tTest-merror:0.133603\n",
      "[79]\tTest-merror:0.132704\n",
      "[80]\tTest-merror:0.132704\n",
      "[81]\tTest-merror:0.131354\n",
      "[82]\tTest-merror:0.131354\n",
      "[83]\tTest-merror:0.131354\n",
      "[84]\tTest-merror:0.128655\n",
      "[85]\tTest-merror:0.128205\n",
      "[86]\tTest-merror:0.125956\n",
      "[87]\tTest-merror:0.125506\n",
      "[88]\tTest-merror:0.125956\n",
      "[89]\tTest-merror:0.125056\n",
      "[90]\tTest-merror:0.125506\n",
      "[91]\tTest-merror:0.124606\n",
      "[92]\tTest-merror:0.123707\n",
      "[93]\tTest-merror:0.123707\n",
      "[94]\tTest-merror:0.123707\n",
      "[95]\tTest-merror:0.124157\n",
      "[96]\tTest-merror:0.123257\n",
      "[97]\tTest-merror:0.123257\n",
      "[98]\tTest-merror:0.123257\n",
      "[99]\tTest-merror:0.123257\n",
      "[100]\tTest-merror:0.122357\n",
      "[101]\tTest-merror:0.121907\n",
      "[102]\tTest-merror:0.120558\n",
      "[103]\tTest-merror:0.121008\n",
      "[104]\tTest-merror:0.121008\n",
      "[105]\tTest-merror:0.120558\n",
      "[106]\tTest-merror:0.120108\n",
      "[107]\tTest-merror:0.120558\n",
      "[108]\tTest-merror:0.120558\n",
      "[109]\tTest-merror:0.121008\n",
      "[110]\tTest-merror:0.120108\n",
      "[111]\tTest-merror:0.119658\n",
      "[112]\tTest-merror:0.119208\n",
      "[113]\tTest-merror:0.119208\n",
      "[114]\tTest-merror:0.119658\n",
      "[115]\tTest-merror:0.119208\n",
      "[116]\tTest-merror:0.118758\n",
      "[117]\tTest-merror:0.119208\n",
      "[118]\tTest-merror:0.118758\n",
      "[119]\tTest-merror:0.119208\n",
      "[120]\tTest-merror:0.118309\n",
      "[121]\tTest-merror:0.118309\n",
      "[122]\tTest-merror:0.118309\n",
      "[123]\tTest-merror:0.118309\n",
      "[124]\tTest-merror:0.119208\n",
      "[125]\tTest-merror:0.119208\n",
      "[126]\tTest-merror:0.119208\n",
      "[127]\tTest-merror:0.119208\n",
      "[128]\tTest-merror:0.119208\n",
      "[129]\tTest-merror:0.119208\n",
      "[130]\tTest-merror:0.119208\n",
      "[131]\tTest-merror:0.119658\n",
      "[132]\tTest-merror:0.119658\n",
      "[133]\tTest-merror:0.119658\n",
      "[134]\tTest-merror:0.119208\n",
      "[135]\tTest-merror:0.119658\n",
      "[136]\tTest-merror:0.119208\n",
      "[137]\tTest-merror:0.119658\n",
      "[138]\tTest-merror:0.118758\n",
      "[139]\tTest-merror:0.118309\n",
      "[140]\tTest-merror:0.117859\n",
      "[141]\tTest-merror:0.117409\n",
      "[142]\tTest-merror:0.117409\n",
      "[143]\tTest-merror:0.116959\n",
      "[144]\tTest-merror:0.116959\n",
      "[145]\tTest-merror:0.116959\n",
      "[146]\tTest-merror:0.116959\n",
      "[147]\tTest-merror:0.116059\n",
      "[148]\tTest-merror:0.116059\n",
      "[149]\tTest-merror:0.116059\n",
      "[150]\tTest-merror:0.116059\n",
      "[151]\tTest-merror:0.11561\n",
      "[152]\tTest-merror:0.116059\n",
      "[153]\tTest-merror:0.116509\n",
      "[154]\tTest-merror:0.116509\n",
      "[155]\tTest-merror:0.116509\n",
      "[156]\tTest-merror:0.116059\n",
      "[157]\tTest-merror:0.11516\n",
      "[158]\tTest-merror:0.11516\n",
      "[159]\tTest-merror:0.11516\n",
      "[160]\tTest-merror:0.11516\n",
      "[161]\tTest-merror:0.11471\n",
      "[162]\tTest-merror:0.11471\n",
      "[163]\tTest-merror:0.11471\n",
      "[164]\tTest-merror:0.11471\n",
      "[165]\tTest-merror:0.11516\n",
      "[166]\tTest-merror:0.11516\n",
      "[167]\tTest-merror:0.11516\n",
      "[168]\tTest-merror:0.11516\n",
      "[169]\tTest-merror:0.11471\n",
      "[170]\tTest-merror:0.11516\n",
      "[171]\tTest-merror:0.11471\n",
      "[172]\tTest-merror:0.11471\n",
      "[173]\tTest-merror:0.11561\n",
      "[174]\tTest-merror:0.11561\n",
      "[175]\tTest-merror:0.11516\n",
      "[176]\tTest-merror:0.11516\n",
      "[177]\tTest-merror:0.11561\n",
      "[178]\tTest-merror:0.116059\n",
      "[179]\tTest-merror:0.11561\n",
      "[180]\tTest-merror:0.116059\n",
      "[181]\tTest-merror:0.11561\n",
      "Stopping. Best iteration:\n",
      "[161]\tTest-merror:0.11471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params['eta'] = 0.05\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    xg_train,\n",
    "    num_boost_round = num_boost_round,\n",
    "    evals = [(xg_test,\"Test\")],\n",
    "    early_stopping_rounds =20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ytest = np.reshape(y_test,(len(X_test), 100))\n",
    "pred = model.predict(xg_test)\n",
    "error_rate = np.sum(np.argmax(pred) != np.argmax(y_test))/np.shape(y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995501574448943"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22., 62., 79., ...,  5., 48., 58.], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_test.get_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020620055707775007"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetEER_(pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('GREYC1.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
